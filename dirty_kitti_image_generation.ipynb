{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# If you are in a fresh environment (e.g., Colab / new venv), uncomment:\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install diffusers transformers accelerate safetensors\n",
    "!pip install pillow kagglehub opencv-python\n"
   ],
   "id": "2950ebb4e008834a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T08:40:24.696316Z",
     "start_time": "2025-12-21T08:40:24.690516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n"
   ],
   "id": "bb7a4424502f8336",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T08:40:24.743355Z",
     "start_time": "2025-12-21T08:40:24.734265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def white_to_alpha(img: Image.Image, threshold: int = 240) -> Image.Image:\n",
    "    img = img.convert(\"RGBA\")\n",
    "    data = np.array(img)\n",
    "    r, g, b, a = data.T\n",
    "    white = (r > threshold) & (g > threshold) & (b > threshold)\n",
    "    data[..., 3][white.T] = 0\n",
    "    return Image.fromarray(data)\n",
    "\n",
    "def load_prompt_files(prompt_file, neg_file, default_prompt=\"\", default_negative=\"\"):\n",
    "    prompt, negative = default_prompt, default_negative\n",
    "    if prompt_file and Path(prompt_file).exists():\n",
    "        prompt = Path(prompt_file).read_text(encoding=\"utf-8\")\n",
    "    if neg_file and Path(neg_file).exists():\n",
    "        negative = Path(neg_file).read_text(encoding=\"utf-8\")\n",
    "    return prompt, negative\n",
    "\n",
    "def init_sd_pipeline(model_id: str, device: str = \"cuda\", dtype=torch.float16):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=dtype)\n",
    "    pipe = pipe.to(device)\n",
    "    pipe.safety_checker = None\n",
    "    try:\n",
    "        pipe.enable_attention_slicing()\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pipe\n",
    "\n",
    "def generate_textures_from_cfg(cfg: dict, pipe: StableDiffusionPipeline):\n",
    "    textures_dir = Path(cfg[\"textures_dir\"])\n",
    "    textures_count = cfg.get(\"textures_count\", 12)\n",
    "    texture_size = cfg.get(\"texture_size\", 512)\n",
    "    prompt_path = cfg.get(\"prompt_path\")\n",
    "    negative_path = cfg.get(\"negative_path\")\n",
    "    prompt, negative = load_prompt_files(prompt_path, negative_path, \"\", \"\")\n",
    "    textures_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i in range(textures_count):\n",
    "        img = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative,\n",
    "            height=texture_size,\n",
    "            width=texture_size,\n",
    "            guidance_scale=7\n",
    "        ).images[0]\n",
    "        img = white_to_alpha(img)\n",
    "        img.save(textures_dir / f\"texture_{i:04d}.png\")\n",
    "    print(f\"Textures generated: {textures_dir}\")\n"
   ],
   "id": "b1532531b2217510",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-21T08:40:24.763310Z",
     "start_time": "2025-12-21T08:40:24.755362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_config(config_path=\"config.json\"):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_mask_params(level: str, cfg):\n",
    "    if level not in cfg[\"mask_config\"]:\n",
    "        raise ValueError(f\"Unknown contamination level: {level}\")\n",
    "    return cfg[\"mask_config\"][level]\n",
    "\n",
    "def generate_contamination_mask_multiscale(size,rng: np.random.Generator,mask_cfg: dict):\n",
    "    \"\"\"\n",
    "    mask_cfg is expected to come directly from:\n",
    "    CFG[\"mask_config\"][level][\"mask\"]\n",
    "    \"\"\"\n",
    "    w, h = size\n",
    "    mask = Image.new(\"L\", (w, h), 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "\n",
    "    spot_specs = mask_cfg[\"spot_specs\"]\n",
    "    base_blur = mask_cfg.get(\"base_blur\", 0)\n",
    "    edge_blur = mask_cfg.get(\"edge_blur\", 0)\n",
    "    add_streaks = mask_cfg.get(\"add_streaks\", False)\n",
    "\n",
    "    # --- blob generation ---\n",
    "    for (\n",
    "        count,\n",
    "        min_r,\n",
    "        max_r,\n",
    "        sub_n,\n",
    "        sub_rf,\n",
    "        inten_min,\n",
    "        inten_max,\n",
    "    ) in spot_specs:\n",
    "\n",
    "        for _ in range(int(count)):\n",
    "            main_r = int(rng.integers(min_r, max_r + 1))\n",
    "\n",
    "            cx = int(rng.integers(main_r, max(main_r + 1, w - main_r)))\n",
    "            cy = int(rng.integers(main_r, max(main_r + 1, h - main_r)))\n",
    "\n",
    "            intensity = int(rng.integers(inten_min, inten_max + 1))\n",
    "\n",
    "            for _ in range(int(sub_n)):\n",
    "                ox = int(rng.integers(-main_r, main_r + 1))\n",
    "                oy = int(rng.integers(-main_r, main_r + 1))\n",
    "\n",
    "                sub_r = max(\n",
    "                    1,\n",
    "                    int(main_r * sub_rf * float(rng.uniform(0.5, 1.6)))\n",
    "                )\n",
    "\n",
    "                sx = cx + ox\n",
    "                sy = cy + oy\n",
    "\n",
    "                x1 = max(0, sx - sub_r)\n",
    "                y1 = max(0, sy - sub_r)\n",
    "                x2 = min(w, sx + sub_r)\n",
    "                y2 = min(h, sy + sub_r)\n",
    "\n",
    "                if x1 < x2 and y1 < y2:\n",
    "                    draw.ellipse((x1, y1, x2, y2), fill=intensity)\n",
    "\n",
    "    # --- streaks ---\n",
    "    if add_streaks:\n",
    "        n_streaks = int(rng.integers(3, 10))\n",
    "        for _ in range(n_streaks):\n",
    "            x1 = int(rng.integers(0, w))\n",
    "            y1 = int(rng.integers(0, h))\n",
    "\n",
    "            length = int(rng.integers(int(0.10 * w), int(0.35 * w)))\n",
    "            angle = float(rng.uniform(-0.6, 0.6))\n",
    "            thickness = int(rng.integers(1, 3))\n",
    "            intensity = int(rng.integers(30, 90))\n",
    "\n",
    "            x2 = int(np.clip(x1 + length * np.cos(angle), 0, w - 1))\n",
    "            y2 = int(np.clip(y1 + length * np.sin(angle), 0, h - 1))\n",
    "\n",
    "            draw.line((x1, y1, x2, y2), fill=intensity, width=thickness)\n",
    "\n",
    "    # --- blur ---\n",
    "    if base_blur > 0:\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(base_blur))\n",
    "    if edge_blur > 0:\n",
    "        mask = mask.filter(ImageFilter.GaussianBlur(edge_blur))\n",
    "\n",
    "    return mask\n"
   ],
   "id": "c80a0223b5e1b89b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T08:54:23.185666Z",
     "start_time": "2025-12-21T08:54:23.172060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_refined_soiling_v2(\n",
    "    clean_img: Image.Image,\n",
    "    texture_img: Image.Image,\n",
    "    rng: np.random.Generator,\n",
    "    level_cfg: dict,\n",
    "    return_mask: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    level_cfg is expected to be:\n",
    "    CFG[\"mask_config\"][level]\n",
    "    \"\"\"\n",
    "\n",
    "    clean_img = clean_img.convert(\"RGB\")\n",
    "    w, h = clean_img.size\n",
    "\n",
    "    # --- generate mask (config-driven) ---\n",
    "    mask_raw = generate_contamination_mask_multiscale(\n",
    "        size=(w, h),\n",
    "        rng=rng,\n",
    "        mask_cfg=level_cfg[\"mask\"]\n",
    "    )\n",
    "\n",
    "    mask_np = np.array(mask_raw).astype(np.float32) / 255.0\n",
    "\n",
    "    # --- edge softness ---\n",
    "    edge_softness = level_cfg.get(\"edge_soft\", 0)\n",
    "    if edge_softness > 0:\n",
    "        k = int(edge_softness) * 2 + 1\n",
    "        mask_np = cv2.GaussianBlur(mask_np, (k, k), 0)\n",
    "\n",
    "    # --- alpha ---\n",
    "    alpha_strength = level_cfg.get(\"alpha\", 1.0)\n",
    "    mask_np = np.clip(mask_np * float(alpha_strength), 0.0, 1.0)\n",
    "\n",
    "    # --- texture ---\n",
    "    tex = texture_img.resize((w, h)).convert(\"RGBA\")\n",
    "    tex_np = np.array(tex).astype(np.float32)\n",
    "    tex_rgb = tex_np[..., :3]\n",
    "    tex_a = tex_np[..., 3] / 255.0\n",
    "\n",
    "    m = np.clip(mask_np * np.clip(tex_a * 0.85, 0.0, 1.0), 0.0, 1.0)\n",
    "    m3 = m[..., None]\n",
    "\n",
    "    # --- blend ---\n",
    "    I = np.array(clean_img).astype(np.float32)\n",
    "    dirty = (1.0 - m3) * I + m3 * tex_rgb\n",
    "\n",
    "    # --- darken ---\n",
    "    darken_strength = level_cfg.get(\"darken\", 0.0)\n",
    "    if darken_strength > 0:\n",
    "        dirty *= (1.0 - float(darken_strength) * m3)\n",
    "\n",
    "    # --- blur ---\n",
    "    blur_strength = level_cfg.get(\"blur\", 0)\n",
    "    if blur_strength > 0:\n",
    "        k = int(blur_strength) * 2 + 1\n",
    "        blurred = cv2.GaussianBlur(dirty, (k, k), 0)\n",
    "        dirty = (1.0 - m3) * dirty + m3 * blurred\n",
    "\n",
    "    # --- haze ---\n",
    "    haze_strength = level_cfg.get(\"haze\", 0.0)\n",
    "    if haze_strength > 0:\n",
    "        dirty = (\n",
    "            (1.0 - float(haze_strength) * m3) * dirty\n",
    "            + (float(haze_strength) * m3) * 255.0\n",
    "        )\n",
    "\n",
    "    dirty_img = Image.fromarray(\n",
    "        np.uint8(np.clip(dirty, 0, 255))\n",
    "    )\n",
    "\n",
    "    if not return_mask:\n",
    "        return dirty_img\n",
    "\n",
    "    mask_img = Image.fromarray(\n",
    "        np.uint8(np.clip(m * 255.0, 0, 255)),\n",
    "        mode=\"L\"\n",
    "    )\n",
    "\n",
    "    return dirty_img, mask_img\n",
    "\n",
    "def build_dirty_kitti_subset(\n",
    "    img_dir: Path,\n",
    "    lbl_dir: Path,\n",
    "    n_samples: int,\n",
    "    overwrite_output: bool,\n",
    "    make_all_presets_per_image: bool,\n",
    "    CFG: dict,\n",
    "    out_root: Path,\n",
    "    img_subset: list[Path] = None,\n",
    "):\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Read from CFG\n",
    "    # -----------------------------\n",
    "    textures_dir = Path(CFG[\"textures_dir\"])\n",
    "    dirty_dir_rel = Path(CFG[\"dirty_dir\"])\n",
    "    clean_dir_rel = Path(CFG[\"clean_dir\"])\n",
    "    masks_dir_rel = Path(CFG[\"masks_dir\"])\n",
    "\n",
    "    save_clean = CFG.get(\"save_clean\", False)\n",
    "    save_masks = CFG.get(\"save_masks\", False)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Output dirs inside out_root\n",
    "    # -----------------------------\n",
    "    dirty_dir_path = out_root / dirty_dir_rel\n",
    "    clean_dir_path = out_root / clean_dir_rel\n",
    "    masks_dir_path = out_root / masks_dir_rel\n",
    "\n",
    "    if overwrite_output:\n",
    "        for d in [dirty_dir_path, clean_dir_path, masks_dir_path]:\n",
    "            if d.exists():\n",
    "                shutil.rmtree(d)\n",
    "\n",
    "    dirty_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    if save_clean:\n",
    "        clean_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    if save_masks:\n",
    "        masks_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Labels folder (always)\n",
    "    out_lbl_dir = dirty_dir_path.parent / \"label_2\"\n",
    "    out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load data\n",
    "    # -----------------------------\n",
    "    if img_subset is not None:\n",
    "        chosen = img_subset\n",
    "    else:\n",
    "        all_imgs = sorted(Path(img_dir).glob(\"*.png\"))\n",
    "        if not all_imgs:\n",
    "            raise FileNotFoundError(f\"No images found in {img_dir}\")\n",
    "        chosen = random.sample(all_imgs, k=min(n_samples, len(all_imgs)))\n",
    "\n",
    "    textures = sorted(textures_dir.glob(\"*.png\"))\n",
    "    if not textures:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No gen_textures found in {textures_dir}. Generate or add PNG gen_textures first.\"\n",
    "        )\n",
    "\n",
    "    missing_labels = 0\n",
    "    saved = 0\n",
    "\n",
    "    # -----------------------------\n",
    "    # Main loop\n",
    "    # -----------------------------\n",
    "    for img_path in chosen:\n",
    "        stem = img_path.stem\n",
    "        lbl_path = Path(lbl_dir) / f\"{stem}.txt\"\n",
    "\n",
    "        if not lbl_path.exists():\n",
    "            missing_labels += 1\n",
    "            continue\n",
    "\n",
    "        clean_img = Image.open(img_path)\n",
    "        tex_img = Image.open(random.choice(textures))\n",
    "\n",
    "        # Save clean image if needed\n",
    "        if save_clean:\n",
    "            clean_img.convert(\"RGB\").save(clean_dir_path / f\"{stem}.png\", format=\"PNG\")\n",
    "\n",
    "        # Select severities\n",
    "        if make_all_presets_per_image:\n",
    "            severities = list(CFG[\"mask_config\"].keys())\n",
    "        else:\n",
    "            severities = [random.choice(list(CFG[\"mask_config\"].keys()))]\n",
    "\n",
    "        for sev in severities:\n",
    "            level_cfg = CFG[\"mask_config\"][sev]\n",
    "\n",
    "            # --- FIX: handle single or tuple return ---\n",
    "            result = apply_refined_soiling_v2(\n",
    "                clean_img=clean_img,\n",
    "                texture_img=tex_img,\n",
    "                rng=rng,\n",
    "                level_cfg=level_cfg,\n",
    "                return_mask=save_masks,\n",
    "            )\n",
    "            if save_masks:\n",
    "                dirty_img, mask_img = result\n",
    "            else:\n",
    "                dirty_img = result\n",
    "                mask_img = None\n",
    "\n",
    "            out_name = f\"{stem}_{sev}\" if make_all_presets_per_image else stem\n",
    "\n",
    "            # Save dirty image\n",
    "            dirty_img.save(dirty_dir_path / f\"{out_name}.png\", format=\"PNG\")\n",
    "\n",
    "            # Save mask if needed\n",
    "            if save_masks and mask_img is not None:\n",
    "                mask_img.save(masks_dir_path / f\"{out_name}.png\", format=\"PNG\")\n",
    "\n",
    "            # Copy label\n",
    "            shutil.copy2(lbl_path, out_lbl_dir / f\"{out_name}.txt\")\n",
    "            saved += 1\n",
    "\n",
    "    print(f\"Done. Saved subset to: {dirty_dir_path.parent}\")\n",
    "    print(f\"Missing labels skipped: {missing_labels}\")\n",
    "    print(f\"Dirty images saved: {saved}\")\n",
    "\n"
   ],
   "id": "5ab39df5bc278753",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T09:08:49.696997Z",
     "start_time": "2025-12-21T09:08:49.690796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_dir = Path(r\"C:\\Users\\yuval\\.cache\\kagglehub\\datasets\\klemenko\\kitti-dataset\\versions\\1\\data_object_image_2\\testing\\image_2\")\n",
    "lbl_dir = Path(r\"C:\\Users\\yuval\\.cache\\kagglehub\\datasets\\klemenko\\kitti-dataset\\versions\\1\\data_object_label_2\\training\\label_2\")\n",
    "out_root = Path(r\"C:\\Users\\yuval\\PycharmProjects\\GenAI_Project\\dirty_imgs\")\n",
    "MAKE_ALL_PRESETS_PER_IMAGE = False\n",
    "mud_cfg = load_config(\"gen_textures/mud/config.json\")\n",
    "water_cfg = load_config(\"gen_textures/water/config.json\")"
   ],
   "id": "2556addac425216f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T08:50:33.232993Z",
     "start_time": "2025-12-21T08:40:24.799538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = init_sd_pipeline(\"runwayml/stable-diffusion-v1-5\")\n",
    "generate_textures_from_cfg(mud_cfg, pipe)\n",
    "generate_textures_from_cfg(water_cfg, pipe)"
   ],
   "id": "c352df31a2c2466",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  29%|â–ˆâ–ˆâ–Š       | 2/7 [00:00<00:01,  4.50it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.69it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textures generated: C:\\Users\\yuval\\PycharmProjects\\GenAI_Project\\textures\\mud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.45it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:34<00:00,  1.46it/s]\n",
      " 10%|â–ˆ         | 5/50 [00:04<00:39,  1.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m pipe = init_sd_pipeline(\u001B[33m\"\u001B[39m\u001B[33mrunwayml/stable-diffusion-v1-5\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      2\u001B[39m generate_textures_from_cfg(mud_cfg, pipe)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mgenerate_textures_from_cfg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwater_cfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpipe\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 36\u001B[39m, in \u001B[36mgenerate_textures_from_cfg\u001B[39m\u001B[34m(cfg, pipe)\u001B[39m\n\u001B[32m     34\u001B[39m textures_dir.mkdir(parents=\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(textures_count):\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     img = \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnegative_prompt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnegative\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m        \u001B[49m\u001B[43mheight\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtexture_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwidth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtexture_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m        \u001B[49m\u001B[43mguidance_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m7\u001B[39;49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m.images[\u001B[32m0\u001B[39m]\n\u001B[32m     43\u001B[39m     img = white_to_alpha(img)\n\u001B[32m     44\u001B[39m     img.save(textures_dir / \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtexture_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m04d\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.png\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    113\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    115\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:1041\u001B[39m, in \u001B[36mStableDiffusionPipeline.__call__\u001B[39m\u001B[34m(self, prompt, height, width, num_inference_steps, timesteps, sigmas, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001B[39m\n\u001B[32m   1038\u001B[39m     latent_model_input = \u001B[38;5;28mself\u001B[39m.scheduler.scale_model_input(latent_model_input, t)\n\u001B[32m   1040\u001B[39m \u001B[38;5;66;03m# predict the noise residual\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1041\u001B[39m noise_pred = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43munet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1042\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlatent_model_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1043\u001B[39m \u001B[43m    \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1044\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1045\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimestep_cond\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimestep_cond\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1047\u001B[39m \u001B[43m    \u001B[49m\u001B[43madded_cond_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43madded_cond_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1048\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1049\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n\u001B[32m   1051\u001B[39m \u001B[38;5;66;03m# perform guidance\u001B[39;00m\n\u001B[32m   1052\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.do_classifier_free_guidance:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d_condition.py:1280\u001B[39m, in \u001B[36mUNet2DConditionModel.forward\u001B[39m\u001B[34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001B[39m\n\u001B[32m   1277\u001B[39m     upsample_size = down_block_res_samples[-\u001B[32m1\u001B[39m].shape[\u001B[32m2\u001B[39m:]\n\u001B[32m   1279\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(upsample_block, \u001B[33m\"\u001B[39m\u001B[33mhas_cross_attention\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m upsample_block.has_cross_attention:\n\u001B[32m-> \u001B[39m\u001B[32m1280\u001B[39m     sample = \u001B[43mupsample_block\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1281\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1282\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtemb\u001B[49m\u001B[43m=\u001B[49m\u001B[43memb\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m        \u001B[49m\u001B[43mres_hidden_states_tuple\u001B[49m\u001B[43m=\u001B[49m\u001B[43mres_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m        \u001B[49m\u001B[43mupsample_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mupsample_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1288\u001B[39m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1289\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1290\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1291\u001B[39m     sample = upsample_block(\n\u001B[32m   1292\u001B[39m         hidden_states=sample,\n\u001B[32m   1293\u001B[39m         temb=emb,\n\u001B[32m   1294\u001B[39m         res_hidden_states_tuple=res_samples,\n\u001B[32m   1295\u001B[39m         upsample_size=upsample_size,\n\u001B[32m   1296\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:2458\u001B[39m, in \u001B[36mCrossAttnUpBlock2D.forward\u001B[39m\u001B[34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask, encoder_attention_mask)\u001B[39m\n\u001B[32m   2456\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2457\u001B[39m         hidden_states = resnet(hidden_states, temb)\n\u001B[32m-> \u001B[39m\u001B[32m2458\u001B[39m         hidden_states = \u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2459\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2460\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2461\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2462\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2463\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2464\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   2465\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n\u001B[32m   2467\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.upsamplers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2468\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m upsampler \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.upsamplers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\transformers\\transformer_2d.py:427\u001B[39m, in \u001B[36mTransformer2DModel.forward\u001B[39m\u001B[34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001B[39m\n\u001B[32m    416\u001B[39m         hidden_states = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m    417\u001B[39m             block,\n\u001B[32m    418\u001B[39m             hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    424\u001B[39m             class_labels,\n\u001B[32m    425\u001B[39m         )\n\u001B[32m    426\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m427\u001B[39m         hidden_states = \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    428\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    429\u001B[39m \u001B[43m            \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    430\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    431\u001B[39m \u001B[43m            \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimestep\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimestep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    433\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    434\u001B[39m \u001B[43m            \u001B[49m\u001B[43mclass_labels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclass_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    435\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    437\u001B[39m \u001B[38;5;66;03m# 3. Output\u001B[39;00m\n\u001B[32m    438\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_input_continuous:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\attention.py:1033\u001B[39m, in \u001B[36mBasicTransformerBlock.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001B[39m\n\u001B[32m   1030\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pos_embed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.norm_type != \u001B[33m\"\u001B[39m\u001B[33mada_norm_single\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1031\u001B[39m         norm_hidden_states = \u001B[38;5;28mself\u001B[39m.pos_embed(norm_hidden_states)\n\u001B[32m-> \u001B[39m\u001B[32m1033\u001B[39m     attn_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mattn2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1034\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnorm_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1035\u001B[39m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1036\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1037\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1038\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1039\u001B[39m     hidden_states = attn_output + hidden_states\n\u001B[32m   1041\u001B[39m \u001B[38;5;66;03m# 4. Feed-forward\u001B[39;00m\n\u001B[32m   1042\u001B[39m \u001B[38;5;66;03m# i2vgen doesn't have this norm ðŸ¤·â€â™‚ï¸\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:605\u001B[39m, in \u001B[36mAttention.forward\u001B[39m\u001B[34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001B[39m\n\u001B[32m    600\u001B[39m     logger.warning(\n\u001B[32m    601\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mcross_attention_kwargs \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munused_kwargs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m are not expected by \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.processor.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m and will be ignored.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    602\u001B[39m     )\n\u001B[32m    603\u001B[39m cross_attention_kwargs = {k: w \u001B[38;5;28;01mfor\u001B[39;00m k, w \u001B[38;5;129;01min\u001B[39;00m cross_attention_kwargs.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m attn_parameters}\n\u001B[32m--> \u001B[39m\u001B[32m605\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprocessor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    606\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    607\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    608\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    609\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    610\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcross_attention_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    611\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:4065\u001B[39m, in \u001B[36mSlicedAttnProcessor.__call__\u001B[39m\u001B[34m(self, attn, hidden_states, encoder_hidden_states, attention_mask)\u001B[39m\n\u001B[32m   4062\u001B[39m key_slice = key[start_idx:end_idx]\n\u001B[32m   4063\u001B[39m attn_mask_slice = attention_mask[start_idx:end_idx] \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m4065\u001B[39m attn_slice = \u001B[43mattn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_attention_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_mask_slice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4067\u001B[39m attn_slice = torch.bmm(attn_slice, value[start_idx:end_idx])\n\u001B[32m   4069\u001B[39m hidden_states[start_idx:end_idx] = attn_slice\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:677\u001B[39m, in \u001B[36mAttention.get_attention_scores\u001B[39m\u001B[34m(self, query, key, attention_mask)\u001B[39m\n\u001B[32m    674\u001B[39m     key = key.float()\n\u001B[32m    676\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m677\u001B[39m     baddbmm_input = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    678\u001B[39m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[32m    679\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    680\u001B[39m     beta = \u001B[32m0\u001B[39m\n\u001B[32m    681\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T09:09:07.418981Z",
     "start_time": "2025-12-21T09:08:52.954792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_imgs = sorted(img_dir.glob(\"*.png\"))\n",
    "half = len(all_imgs) // 2\n",
    "mud_imgs = all_imgs[:half]\n",
    "water_imgs = all_imgs[half:]\n",
    "\n",
    "build_dirty_kitti_subset(\n",
    "    img_dir=img_dir,\n",
    "    lbl_dir=lbl_dir,\n",
    "    n_samples=len(mud_imgs),\n",
    "    overwrite_output=True,\n",
    "    make_all_presets_per_image=MAKE_ALL_PRESETS_PER_IMAGE,\n",
    "    CFG=mud_cfg,\n",
    "    out_root=out_root / \"mud\",\n",
    "    img_subset=mud_imgs[:50]\n",
    ")\n",
    "\n",
    "build_dirty_kitti_subset(\n",
    "    img_dir=img_dir,\n",
    "    lbl_dir=lbl_dir,\n",
    "    n_samples=len(water_imgs),\n",
    "    overwrite_output=True,\n",
    "    make_all_presets_per_image=MAKE_ALL_PRESETS_PER_IMAGE,\n",
    "    CFG=water_cfg,\n",
    "    out_root=out_root / \"water\",\n",
    "    img_subset=water_imgs[:50]\n",
    ")\n"
   ],
   "id": "a85957e9b0f76bd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved subset to: C:\\Users\\yuval\\PycharmProjects\\GenAI_Project\\dirty_imgs\\mud\n",
      "Missing labels skipped: 0\n",
      "Dirty images saved: 50\n",
      "Done. Saved subset to: C:\\Users\\yuval\\PycharmProjects\\GenAI_Project\\dirty_imgs\\water\n",
      "Missing labels skipped: 0\n",
      "Dirty images saved: 50\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (GPU)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
